# ğŸ¬ Pipeline Data Streaming Real-Time - Movies Analytics

Pipeline streaming real-time untuk menganalisis data dari Netflix, Amazon Prime, dan Disney+ menggunakan Apache Kafka, Spark Streaming, PostgreSQL, dan Power BI.


example : https://drive.google.com/drive/folders/1NJFG7emT7nTEz-iLEV9Pl51wExyBsKOz?usp=sharing

![Project Status](https://img.shields.io/badge/status-active-success.svg)
![Python](https://img.shields.io/badge/python-3.11-blue.svg)
![Spark](https://img.shields.io/badge/spark-3.5.6-orange.svg)
![Kafka](https://img.shields.io/badge/kafka-7.5.0-black.svg)

## ğŸ“‹ Daftar Isi

- [Gambaran Umum](#gambaran-umum)
- [Arsitektur](#arsitektur)
- [Teknologi](#teknologi)
- [Struktur Proyek](#struktur-proyek)
- [Instalasi](#instalasi)
- [Cara Menjalankan](#cara-menjalankan)
- [Transformasi Data](#transformasi-data)
- [Power BI](#power-bi)
- [Monitoring](#monitoring)
- [Troubleshooting](#troubleshooting)

---

## ğŸ¯ Gambaran Umum

Project ini membangun **pipeline streaming data real-time** yang mengumpulkan, memproses, dan menganalisis data film dan serial TV dari 3 platform streaming terbesar:

- ğŸ”´ **Netflix** (~8,800 judul)
- ğŸ”µ **Amazon Prime** (~9,600 judul)
- â­ **Disney+** (~1,400 judul)

### Tujuan Proyek

1. âœ… Membangun pipeline streaming end-to-end
2. âœ… Pemrosesan data secara real-time
3. âœ… Dashboard analitik interaktif
4. âœ… Deployment siap produksi dengan Docker

### Hasil Akhir

- Dashboard Power BI interaktif
- Real-time insights dari streaming data
- Analisis perbandingan antar platform
- Visualisasi kategori dan distribusi geografis

---

## ğŸ—ï¸ Arsitektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Netflix   â”‚ â”‚ Amazon Primeâ”‚ â”‚   Disney+   â”‚
â”‚   CSV File  â”‚ â”‚   CSV File  â”‚ â”‚   CSV File  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                â”‚                â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚   Producer  â”‚
                 â”‚   (Python)  â”‚
                 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚    Kafka    â”‚
                 â”‚    Topic    â”‚
                 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚    Spark    â”‚
                 â”‚  Streaming  â”‚
                 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚ PostgreSQL  â”‚
                 â”‚  Database   â”‚
                 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  Power BI   â”‚
                 â”‚  Dashboard  â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Teknologi

| Komponen | Teknologi | Versi | Fungsi |
|----------|-----------|-------|--------|
| **Message Broker** | Apache Kafka | 7.5.0 | Streaming pesan real-time |
| **Stream Processing** | Apache Spark | 3.5.6 | Pemrosesan & transformasi |
| **Database** | PostgreSQL | 15 | Penyimpanan data |
| **Visualization** | Power BI Desktop | - | Dashboard analitik |
| **Containerization** | Docker Compose | - | Orkestrasi container |
| **Programming** | Python | 3.11 | Development |
| **Notebook** | Jupyter | - | Testing & debugging |

### Docker Containers

Pipeline ini menggunakan **8 Docker containers**:

1. **Zookeeper** - Koordinasi Kafka
2. **Kafka** - Message broker
3. **Kafka UI** - Monitoring Kafka (port 8080)
4. **PostgreSQL** - Database (port 5432)
5. **Spark Master** - Cluster manager (port 8081)
6. **Spark Worker 1** - Processing node (port 8082)
7. **Spark Worker 2** - Processing node (port 8083)
8. **Producer** - Data ingestion service

---

## ğŸ“ Struktur Proyek

```
streaming-data-pipeline/
â”‚
â”œâ”€â”€ consumer/
â”‚   â”œâ”€â”€ kafka_spark_consumer.py    # Consumer untuk production (Docker)
â”‚   â””â”€â”€ requirements.txt            # Dependencies Python
â”‚
â”œâ”€â”€ producer/
â”‚   â”œâ”€â”€ movies_producer.py          # Producer untuk kirim data ke Kafka
â”‚   â”œâ”€â”€ requirements.txt            # Dependencies Python
â”‚   â””â”€â”€ Dockerfile                  # Container image untuk producer
â”‚
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ netflix_titles.csv          # Data Netflix
â”‚   â”œâ”€â”€ amazon_prime_titles.csv     # Data Amazon Prime
â”‚   â””â”€â”€ disney_plus_titles.csv      # Data Disney+
â”‚
â”œâ”€â”€ jars/
â”‚   â””â”€â”€ postgresql-42.2.20.jar      # JDBC driver PostgreSQL
â”‚
â”œâ”€â”€ spark-output/
â”‚   â”œâ”€â”€ bronze/                     # Raw data (Parquet)
â”‚   â”œâ”€â”€ silver/                     # Cleaned data (Parquet)
â”‚   â””â”€â”€ gold/                       # Aggregated data (unused)
â”‚
â”œâ”€â”€ Dockerfile                      # Image untuk Spark containers
â”œâ”€â”€ docker-compose.yaml             # Orkestrasi semua services
â”œâ”€â”€ init-db.sql                     # Database schema
â”œâ”€â”€ Makefile                        # Helper commands
â”œâ”€â”€ SparkNotebook.ipynb             # Testing notebook (local)
â”œâ”€â”€ README.md                       # Dokumentasi (file ini)
â””â”€â”€ QUICK-REFERENCE.md              # Quick reference guide
```

---

## ğŸš€ Instalasi

### Prerequisites

Pastikan sudah terinstall:

- âœ… **Docker Desktop** (minimum 8GB RAM)
- âœ… **Docker Compose** (included in Docker Desktop)
- âœ… **Git** (untuk clone repository)
- âœ… **10GB disk space**

Optional (untuk testing):
- âœ… **Python 3.11**
- âœ… **Jupyter Notebook**
- âœ… **Power BI Desktop**

### Langkah Instalasi

1. **Clone Repository**

```bash
git clone https://github.com/yourusername/streaming-data-pipeline.git
cd streaming-data-pipeline
```

2. **Siapkan Direktori**

```bash
mkdir
